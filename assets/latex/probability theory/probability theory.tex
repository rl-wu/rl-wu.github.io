\documentclass[12pt,a4paper]{article}

% 中文支持
\usepackage[UTF8]{ctex}

% 数学宏包
\usepackage{amsmath,amsfonts,amssymb,blkarray,mathrsfs,amsthm}

%使用分条的列表
\usepackage{enumitem}

%插入代码
\usepackage{listings}
\usepackage[most]{tcolorbox}

% 图片和表格
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{subcaption}

% 页面布局
\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=3cm,bottom=3cm}
\usepackage{multirow}


% 超链接
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    citecolor=black,
    urlcolor=red
}


% 页眉和页脚
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{概率论笔记}
\lhead{WRL}
\rfoot{第 \thepage 页}

% 颜色
\usepackage{xcolor}

\newtheorem{thm}{定理}[subsection]  % 在每个章节重新编号
\newtheorem{lemma}{引理}[subsection]    % 在每个章节重新编号
\newtheorem{corollary}{推论}[subsection] % 在每个章节重新编号
\newtheorem{definition}{定义}[subsection] % 在每个章节内自动编号

\begin{document}
\begin{center}
\section*{摘要}
\end{center}

我自学使用的教材为《概率论基础》，在此笔记中主要记录书中的核心内容，配以心得体会。


{\centering\tableofcontents}

\newpage
\section{公理化结构}
\subsection{事件域}
\begin{definition}[样本空间]
    对于(随机)试验,可能出现的结果称为\textbf{样本点}$\omega$,样本点全体构成\textbf{样本空间}$\varOmega$.
\end{definition}
在概率论中一般假定样本空间是给定的,这是必要的抽象,是我们能更好地把我住随机变量的本质,类比于线性空间.
\begin{definition}
    \textbf{事件}定义为样本空间$\varOmega$的一个子集,称事件发生当且仅当它所包含的某一个样本点出现.
\end{definition}
在此定义下,集合的包含关系诱导了事件的包含关系,补集对应于逆事件,或称对立事件,两个集合的交意味着两个事件的交意味着两个事件同时发生,并集意味着至少发生一个.

一般不把样本空间$\varOmega$的一切子集作为事件,这会带来困难,譬如在几何概率中把不可测集也作为事件将会带来不可克服的麻烦.
另一方面,又必须把感兴趣的事件都包括进来,所以要求事件全体$\mathscr{F}$组成一个$\sigma$代数.
\begin{definition}[事件域]
    若$\mathscr{F}$是由样本空间$\varOmega$的一些子集构成的一个\textbf{$\sigma$代数},则称它为\textbf{事件域},
    $\mathscr{F}$中的元素称为\textbf{事件},$\varOmega$称为必然事件,$\varnothing$称为不可能事件.
\end{definition}
需要特别注意的是由给定的$\varOmega$的一个非空集族$\mathscr{G}$,必定存在由$\mathscr{G}$生成的$\sigma$代数.这种方法可以定义Borel集.
\subsection{概率}
\begin{definition}[概率]
    定义在事件域$\mathscr{F}$上的一个集合函数$P$称为\textbf{概率},如果它满足如下三个要求:
    \begin{enumerate}[label=(\roman*),font=\upshape]
        \item $P(A)\geq 0,\forall A \in \mathscr{F}$
        \item $P(\varOmega)=1$
        \item $\forall A_i \in \mathscr{F},i = 1,2, \cdots$,若$A_i$两两互不相容,则
        \[P(\sum_{i=1}^{\infty}A_i) = \sum_{i=1}^{\infty}P(A_i)\]
      \end{enumerate}
\end{definition}
实际上实变函数中的一般测度在全空间的测度为1时就是概率.

有了可数可加性,我们便有\textbf{下连续性}.实际上若$A_i \in \mathscr{F},i = 1,2, \cdots$且$A_i$两两互不相容,则有
\[P(\sum_{i = 1}^n A_i) = \sum_{i = 1}^n P(A_i) \]两边取极限,右边由于是级数和,1显然是其上界,所以级数和存在,于是有:
\[\lim_{n\rightarrow \infty}P(\sum_{i = 1}^n A_i) = \sum_{i=1}^{\infty} P(A_i) \overset{\text{\tiny{可数可加}}}{=} P(\sum_{i=1}^{\infty}A_i) \]
即对于单调不减的集合列,其\textbf{概率的极限等于极限集合的概率}.考虑补集,可以知道概率也是上连续的.另外,有限可加且下连续与可数可加等价.
\subsection{概率空间}
\begin{definition}[概率空间]
    $\varOmega$是样本空间,$\mathscr{F}$是事件域,$P$是概率,则称三元总体$(\varOmega.\mathscr{F},P)$为\textbf{概率空间}.
\end{definition}
最后这里放个最大似然估计法,因为书上第一章提到了,我觉得比较重要就记下来了,以后有更合适的地方再搬过去吧.
\begin{definition}
    把概率 $p(n)$ 看作未知参数$n$的函数,称为\textbf{似然函数},在通过求其最大值而得到$n$的估计,这就是数理统计中的\textbf{最大似然估计法}
\end{definition}
\newpage
\section{条件概率与统计独立性}
\subsection{条件概率}
\begin{definition}[条件概率]
    设$(\varOmega,\mathscr{F},P)$为一个概率空间,$B \in \mathscr{F},P(B)>0$,则对任意$A\in\mathscr{F}$,记
    \[P(A|B) = \frac{P(AB)}{P(B)}\]
    并称$P(A|B)$为\textbf{在事件B发生的条件下事件A发生的条件概率}.
\end{definition}
概率论的重要课题之一就是通过简单事件的概率推算处复杂事件的概率，这里全概率公式起着重要作用.
\begin{definition}[全概率公式]
    设事件$A_1,A_2,\cdots,A_n,\cdots$是样本空间$\varOmega$的一个分割,亦称完备事件组,即$A_i$两两互不相容,而且$\sum_{i=1}^{\infty}A_i = \varOmega$,这样便有
    $B = \sum_{i=1}^{\infty}A_i B$,由概率的可加性与条件概率定义可得
    \[P(B) = \sum_{i=1}^{\infty}P(A_i)P(B|A_i)\]
    此公式称为\textbf{全概率公式}
\end{definition}
\begin{definition}[Bayes公式]
    若B总是与两两互不相容的事件$A_1,A_2,\cdots$之一同时发生,即$B = \sum_{i=1}^{\infty}BA_i$,结合条件概率的定义与全概率公式得
    \[P(A_i|B) = \frac{P(A_i)P(B|A_i)}{P(B)} = \frac{P(A_i)P(B|A_i)}{\sum_{i=1}^{\infty} P(A_i)P(B|A_i)}\]
    此公式称为\textbf{Bayes公式}
\end{definition}
Bayes公式得应用场景十分广泛,比如医生为了诊断病人是患了$A_1,\cdots,A_n$这几个疾病中的哪一种,可以先对病人进行检查确定指标$B$,此时利用指标$B$,可以计算相关概率.

Bayes公式中的$P(A_i)$称为\textbf{先验概率},反映了各种原因发生的可能性大小,实际应用中一般是以往经验的总结,试验前便已知道.条件概率$P(A_i|B)$称为\textbf{后验概率},
它反映了试验发生后各种原因发生的可能性大小的条件概率.
\subsection{事件独立性}
\begin{definition}[事件独立性]
    对$n$个事件$A_1,A_2,\cdots,A_n$,若对于所有可能的组合$1\leq i<j<k<\cdots\leq n$成立着
    \[\begin{aligned}
        & P(A_i A_j) = P(A_i)P(A_j)\\
        & P(A_i A_j A_k) = P(A_i)P(A_j)P(A_k)\\
        & \cdots\\
        &P(A_1 A_2 \cdots A_n) = P(A_1)P(A_2)\cdots P(A_n)
    \end{aligned}\]
    则称$A_1,A_2,\cdots,A_n$\textbf{相互独立}
\end{definition}
事件独立性的每个条件都是必要的,与集合不同,集合两两相交为空集便有任意的交为空集,但是这与事件独立性不同,下面是三个事件两两独立,但三个事件一起并不独立的例子.

考虑一个均匀的正四面体,第一面染成1色,第二面染成2色,第三面染成3色,第四面同时染上1,2,3三种颜色,现在记事件$A,B,C$分别为投一次四面体出现1,2,3色朝下的事件,
因此$P(A)=P(B)=P(C)=\frac{1}{2},P(AB)=P(BC)=P(AC)=\frac{1}{4}$,即此时事件$A,B,C$两两独立,但是$P(ABC)=\frac{1}{4}\neq\frac{1}{8}=P(A)P(B)P(C)$,即三个事件一起并不一致独立.

有了事件的独立性之后可以定义\textbf{试验的独立性}与\textbf{重复独立试验},不在这里写了.
\subsection{伯努利试验}
\begin{definition}[伯努利试验]
    把事件域$\mathscr{F}$取为$\{\varnothing,A,\bar{A},\varOmega\}$,并称出现$A$为成功,出现$\bar{A}$为失败,这种只有两个可能结果的试验称为\textbf{伯努利试验}.
    考虑重复进行$n$次独立的伯努利试验,这种试验称作\textbf{$n$重伯努利试验}
\end{definition}
\begin{definition}[二项分布]
    记伯努利试验中$P(A)=p,P(\bar{A})=q=1-p$, 记$n$重伯努利试验中事件$A$出现$k$次的概率为$b(k;n,p)$, 那么有$b(k;n,p)= {n\choose k}p^kq^{n-k},k=1,2,\cdots,n$, $b(k;n,p)$称为\textbf{二项分布}
\end{definition}
二项分布的结果也可以容易地推广到$n$次重复独立试验且每次试验可能有若干有限个结果的情形,此时称为\textbf{多项分布}.

\subsection{二项分布与泊松分布}
二项分布定义如上,我们下面考虑二项分布的性质,由于\[\frac{b(k;n,p)}{b(k-1;,b,p)}=1 + \frac{(n+1)p-k}{kq}\]
于是$k=\left[(n+1)p\right]$为最可能成功次数,这也是使得$b(k;n,p)$最大的项,此时也称为中心项.
\begin{thm}[二项分布的泊松逼近]
    在独立试验中,以$p_n$代表事件$A$在试验中出现的概率,它与试验总数$n$有关,如果 $n\rightarrow \infty$ 时 $np_n\rightarrow \lambda$,则有
    \[b(k;n,p_n)\rightarrow \frac{\lambda^k}{k!}e^{-\lambda}\]
    其中$p(k;\lambda)=\frac{\lambda^k}{k!}e^{-\lambda}$称为\textbf{泊松分布}
\end{thm}

\newpage
\section{随机变量与分布函数}
\subsection{随机变量及其分布}
\begin{definition}[随机变量]
    设$\xi(\omega)$是定义于概率空间$(\varOmega,\mathscr{F},P)$上的单值实函数,其中$\omega$是样本点,如果对于直线上任一Borel点集$B$,有
    \[\{\omega:\xi(\omega)\in B\}\in \mathscr{F}\]
    则称$\xi(\omega)$为\textbf{随机变量},而$P\{\omega:\xi(\omega)\in B\}$称为随机变量$\xi(\omega)$的\textbf{概率分布}.
\end{definition}
随机变量其实就是测度空间上的可测函数.
\begin{definition}[分布函数]
    称\[F(x)=P\{\omega:\xi(\omega)<x\},\ -\infty<x<\infty\]
    为随机变量$\xi(\omega)$的\textbf{分布函数}.
\end{definition}
为了书写方便,通常把“随机变量$\xi(\omega)$服从分布函数$F(x)$”简记作$\xi(\omega)\sim F(x)$.
由分布函数的定义立刻得到\[P\{a\leq \xi (\omega)<b \} = F(b)-F(a)\]
由此定义的分布函数具有\textbf{左连续性},即$F(x-0)=F(x)$,这里左连续而不一定右连续是因为分布函数的定义中不取等号导致的,具体来说更本质的原因是
 $[x_n,x )$ 在$x_n\rightarrow x$时会趋近空集.分布函数的定义还能推导出以下等式:
\[\begin{aligned}
    P\{\xi(\omega)=a\}=&F(a+0)-F(a) \\ P\{\xi(\omega)\leq a\} =& F(a+0)
\end{aligned}\]
这些公式基本都来源于\textbf{概率的下连续性},即\textbf{概率的极限等于极限集合的概率}

\begin{definition}[离散型随机变量]
    设$\{x_i\}$为离散型随机变量的所有可能值,而$p(x_i)$是$\xi$取$x_i$的概率,即\[P\{\xi = x_i\} = p(x_i),i=1,2,\cdots\]
    那么称$\{p(x_i),i=1,2,\cdots\}$为随机变量$\xi$的概率分布.
\end{definition}
由此我们可以求出分布函数\[F(x) = P\{\xi(\omega)<x\}=\sum_{x_k<x}p(x_k)\]
此时分布函数为一个跳跃的阶梯函数.另外,常用\textbf{分布列}表出离散型随机变量的概率分布.
\begin{definition}[连续型随机变量]
    连续型随机变量$\xi$可取某个区间$[c,d]$或者$(-\infty,\infty)$中的一切值,而且其分布函数$F(x)$是绝对连续函数,
    即存在可积函数$p(x)$,使得\[F(x) = \int_{-\infty}^x p(t) \mathrm{d}t\]此时称$p(x)$为$\xi$的\textbf{密度函数}.
\end{definition}
这里的绝对连续是实变函数中的概念,$p(x)$在零测集上作改动也不影响分布函数,
所以对于密度函数$p(x)$的论断通常都是在“几乎处处”的意义上成立.这些都是实变函数中老生常谈的内容.

\subsection{}



\end{document}